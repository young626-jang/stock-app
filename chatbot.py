import streamlit as st
from polygon import RESTClient
from datetime import datetime, timedelta
from collections import defaultdict
import google.generativeai as genai
from PIL import Image
import io

# ==========================================
# [ê¸°ë³¸ ì„¤ì •] í˜ì´ì§€ ì œëª© ë° ì•„ì´ì½˜
# ==========================================
st.set_page_config(
    page_title="ë¯¸êµ­ ì£¼ì‹ ì„¸ë ¥ íƒì§€ê¸°",
    page_icon="ğŸš€",
    layout="centered"
)

# ==========================================
# [ë³´ì•ˆ ì„¤ì •] í™˜ê²½ë³€ìˆ˜(Secrets)ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
# ==========================================
try:
    # ë‚´ ì»´í“¨í„°ì˜ .streamlit/secrets.toml ë˜ëŠ” ì›¹ ì„œë²„ì˜ Secretsì—ì„œ ê°€ì ¸ì˜´
    API_KEY = st.secrets["POLYGON_API_KEY"]
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
except (FileNotFoundError, KeyError) as e:
    st.error("ğŸš¨ API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
    st.warning("`.streamlit/secrets.toml` íŒŒì¼ì— POLYGON_API_KEYì™€ GEMINI_API_KEYë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
    st.stop()

# Gemini API ì´ˆê¸°í™”
genai.configure(api_key=GEMINI_API_KEY)

# ==========================================
# [ë©”ì¸ í™”ë©´ êµ¬ì„±]
# ==========================================
# ==========================================
# [ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”] - ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥
# ==========================================
if "analysis_data" not in st.session_state:
    st.session_state.analysis_data = None
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

st.title("ğŸš€ ë¯¸êµ­ ì£¼ì‹ ì„¸ë ¥ íƒì§€ê¸°")
st.markdown("##### ğŸ¤– ì„¸ë ¥ì˜ í‰ë‹¨ê°€(VWAP)ì™€ ì§€ì§€ì„ ì„ ë¶„ì„í•©ë‹ˆë‹¤.")

# ì¢…ëª© ì…ë ¥ì°½ (ê¸°ë³¸ê°’ IONQ)
ticker = st.text_input("ë¶„ì„í•  ì¢…ëª© ì½”ë“œ (ì˜ˆ: NVDA, RKLB)", value="IONQ").upper().strip()

# ë²„íŠ¼ í´ë¦­ ì‹œ ì‹¤í–‰
if st.button("ì„¸ë ¥ ì˜ë„ ë¶„ì„ ì‹œì‘ ğŸ”", type="primary"):
    with st.spinner(f"'{ticker}' ë°ì´í„°ë¥¼ ì”¹ì–´ë¨¹ëŠ” ì¤‘... ì±±ì±± ğŸ¥£"):
        try:
            # 1. í´ë¼ì´ì–¸íŠ¸ ì—°ê²°
            client = RESTClient(API_KEY)
            
            # 2. ë‚ ì§œ ì„¤ì • (ìµœê·¼ 14ì¼)
            end_date = datetime.now()
            start_date = end_date - timedelta(days=14)
            
            str_start = start_date.strftime("%Y-%m-%d")
            str_end = end_date.strftime("%Y-%m-%d")

            # 3. ë°ì´í„° ìˆ˜ì§‘
            aggs = []
            for a in client.list_aggs(ticker, 1, "minute", str_start, str_end, limit=50000):
                aggs.append(a)

            # 4. ë°ì´í„° ê²€ì¦
            if not aggs:
                st.error(f"âŒ [{ticker}] ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í‹°ì»¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            else:
                # ----------------------------------
                # 5. í•µì‹¬ ë¶„ì„ ë¡œì§ (VWAP & ì§€ì§€ì„ )
                # ----------------------------------
                total_volume = 0
                total_pv = 0
                price_volume = defaultdict(int)
                current_price = aggs[-1].close

                for c in aggs:
                    # VWAP ê³„ì‚°ìš© (í‰ê· ê°€ * ê±°ë˜ëŸ‰)
                    typical_price = (c.high + c.low + c.close) / 3
                    total_pv += (typical_price * c.volume)
                    total_volume += c.volume
                    
                    # ë§¤ë¬¼ëŒ€ ê³„ì‚° (ì†Œìˆ˜ì  1ìë¦¬ ë°˜ì˜¬ë¦¼)
                    price_volume[round(c.close, 1)] += c.volume

                # ìµœì¢… ê³„ì‚°
                vwap = total_pv / total_volume if total_volume > 0 else 0
                
                # ê°€ì¥ ê±°ë˜ëŸ‰ì´ ë§ì•˜ë˜ ê°€ê²© (ì§€ì§€ì„ )
                top_support = sorted(price_volume.items(), key=lambda x: x[1], reverse=True)[0][0]
                
                # ê´´ë¦¬ìœ¨ (%)
                diff_per = ((current_price - vwap) / vwap) * 100

                # ----------------------------------
                # 6. ê²°ê³¼ í™”ë©´ ì¶œë ¥ (ëª¨ë°”ì¼ ìµœì í™”)
                # ----------------------------------
                st.success("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

                # ì¹´ë“œ í˜•íƒœë¡œ ì£¼ìš” ì§€í‘œ ë³´ì—¬ì£¼ê¸°
                col1, col2, col3 = st.columns(3)
                col1.metric("í˜„ì¬ ì£¼ê°€", f"${current_price}")
                col2.metric("ì„¸ë ¥ í‰ë‹¨ (VWAP)", f"${vwap:.2f}", f"{diff_per:.2f}%")
                col3.metric("ê°•ë ¥ ì§€ì§€ì„ ", f"${top_support}")

                st.divider() # êµ¬ë¶„ì„ 

                # ë¶„ì„ ë°ì´í„° ì €ì¥
                analysis_data = {
                    "ticker": ticker,
                    "current_price": current_price,
                    "vwap": vwap,
                    "top_support": top_support,
                    "diff_per": diff_per,
                    "total_volume": total_volume
                }
                st.session_state.analysis_data = analysis_data

                # ğŸ¤– AIì˜ 3ì¤„ ìš”ì•½ íŒë‹¨
                st.subheader("ğŸ¤– AIì˜ íŒë‹¨")

                if current_price < top_support:
                    st.error("ğŸš¨ [ìœ„í—˜] ì§€ì§€ì„ ì´ ê¹¨ì¡ŒìŠµë‹ˆë‹¤!")
                    st.write(f"ë°”ë‹¥ì´ë¼ê³  ìƒê°í–ˆë˜ **${top_support}** ê°€ê²©ì´ ë¬´ë„ˆì¡ŒìŠµë‹ˆë‹¤. ì§€ê¸ˆ ë§¤ìˆ˜í•˜ë©´ ë¬¼ë¦´ í™•ë¥ ì´ ë†’ìŠµë‹ˆë‹¤.")
                elif current_price < vwap:
                    st.success("âœ… [ê¸°íšŒ] ì„¸ë ¥ë³´ë‹¤ ì‹¸ê²Œ ì‚´ ê¸°íšŒ!")
                    st.write(f"ê¸°ê´€ë“¤ì˜ í‰ê·  ë‹¨ê°€(**${vwap:.2f}**)ë³´ë‹¤ ì €ë ´í•©ë‹ˆë‹¤. ë¶„í•  ë§¤ìˆ˜í•˜ê¸° ì¢‹ì€ êµ¬ê°„ì…ë‹ˆë‹¤.")
                else:
                    st.warning("ğŸ”¥ [ì£¼ì˜] ì´ë¯¸ ë§ì´ ì˜¬ëìŠµë‹ˆë‹¤.")
                    st.write(f"ì„¸ë ¥ë“¤ë„ ì´ë¯¸ ìˆ˜ìµ êµ¬ê°„ì…ë‹ˆë‹¤. ì¶”ê²© ë§¤ìˆ˜ëŠ” ìì œí•˜ì„¸ìš”.")

        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

# ==========================================
# [AI ëŒ€í™”í˜• ì±—ë´‡] - Geminiì™€ì˜ ì‹¤ì‹œê°„ ëŒ€í™”
# ==========================================
st.divider()
st.subheader("ğŸ’¬ AI ê¸ˆìœµ ì „ë¬¸ê°€ì™€ ëŒ€í™”í•˜ê¸°")

if st.session_state.analysis_data:
    data = st.session_state.analysis_data
    system_prompt = f"""ë‹¹ì‹ ì€ ë¯¸êµ­ ì£¼ì‹ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

í˜„ì¬ ë¶„ì„ ì¤‘ì¸ ì¢…ëª©: {data['ticker']}
- í˜„ì¬ ì£¼ê°€: ${data['current_price']}
- ì„¸ë ¥ í‰ë‹¨ê°€(VWAP): ${data['vwap']:.2f}
- ê°•ë ¥ ì§€ì§€ì„ : ${data['top_support']}
- ê´´ë¦¬ìœ¨: {data['diff_per']:.2f}%
- ì´ ê±°ë˜ëŸ‰: {data['total_volume']}

ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì„¸í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
ê¸°ìˆ ì  ë¶„ì„, íˆ¬ì ì „ëµ, ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë“±ì— ëŒ€í•´ ì¡°ì–¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ëª¨ë“  ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì œê³µí•˜ì„¸ìš”."""
else:
    system_prompt = "ë‹¹ì‹ ì€ ë¯¸êµ­ ì£¼ì‹ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ íˆ¬ì ê´€ë ¨ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ìì„¸í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”."

# ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
for message in st.session_state.chat_history:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥
user_input = st.chat_input("íˆ¬ì ê´€ë ¨ ì§ˆë¬¸ì„ í•˜ì„¸ìš”... (ì˜ˆ: ì§€ê¸ˆ ë§¤ìˆ˜í•´ë„ ë ê¹Œìš”?)")

if user_input:
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    st.session_state.chat_history.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # AI ì‘ë‹µ ìƒì„±
    with st.spinner("ğŸ¤– AIê°€ ìƒê° ì¤‘ì…ë‹ˆë‹¤..."):
        try:
            # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ìë™ ì„ íƒ
            available_models = [m.name for m in genai.list_models() if "generateContent" in m.supported_generation_methods]

            model_priority = ["gemini-2.0-flash", "gemini-1.5-flash", "gemini-1.5-pro"]
            selected_model = "gemini-1.5-flash"  # ê¸°ë³¸ê°’

            for model_name in model_priority:
                if any(model_name in m for m in available_models):
                    selected_model = model_name
                    break

            model = genai.GenerativeModel(selected_model)

            # ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
            messages = f"{system_prompt}\n\n"
            for msg in st.session_state.chat_history[:-1]:  # ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ ì œì™¸ (ì´ë¯¸ ìœ„ì— ìˆìŒ)
                role = "ì‚¬ìš©ì" if msg["role"] == "user" else "ì „ë¬¸ê°€"
                messages += f"{role}: {msg['content']}\n\n"
            messages += f"ì‚¬ìš©ì: {user_input}"

            response = model.generate_content(messages)
            ai_response = response.text

            # AI ì‘ë‹µ ì €ì¥ ë° í‘œì‹œ
            st.session_state.chat_history.append({"role": "assistant", "content": ai_response})
            with st.chat_message("assistant"):
                st.markdown(ai_response)
        except Exception as e:
            st.error(f"AI ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
else:
    if not st.session_state.analysis_data:
        st.info("ğŸ“Š ë¨¼ì € ì¢…ëª©ì„ ë¶„ì„í•´ì£¼ì„¸ìš”!")

# ==========================================
# [íƒ­ ê¸°ëŠ¥] - ì°¨íŠ¸ ë¶„ì„ & ë‰´ìŠ¤ ë¶„ì„
# ==========================================
st.divider()
tab1, tab2 = st.tabs(["ğŸ“Š ì°¨íŠ¸ ë¶„ì„", "ğŸ“° ë‰´ìŠ¤ ë¶„ì„"])

# ==========================================
# [íƒ­ 1] ì°¨íŠ¸ ì—…ë¡œë“œ ë¶„ì„
# ==========================================
with tab1:
    st.subheader("ì°¨íŠ¸ ì´ë¯¸ì§€ ë¶„ì„")
    st.write("ì£¼ì‹ ì°¨íŠ¸ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ AIê°€ ê¸°ìˆ ì  ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.")

    uploaded_chart = st.file_uploader(
        "ì°¨íŠ¸ ì´ë¯¸ì§€ ì—…ë¡œë“œ (PNG, JPG, GIF)",
        type=["png", "jpg", "jpeg", "gif"],
        key="chart_uploader"
    )

    if uploaded_chart is not None:
        # ì´ë¯¸ì§€ í‘œì‹œ
        image = Image.open(uploaded_chart)
        st.image(image, caption="ì—…ë¡œë“œëœ ì°¨íŠ¸", use_column_width=True)

        # AI ë¶„ì„
        if st.button("ğŸ” ì°¨íŠ¸ ë¶„ì„ ì‹œì‘", key="analyze_chart"):
            with st.spinner("ì°¨íŠ¸ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                try:
                    # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì„ íƒ
                    available_models = [m.name for m in genai.list_models() if "generateContent" in m.supported_generation_methods]
                    model_priority = ["gemini-2.0-flash", "gemini-1.5-flash", "gemini-1.5-pro"]
                    selected_model = "gemini-1.5-flash"

                    for model_name in model_priority:
                        if any(model_name in m for m in available_models):
                            selected_model = model_name
                            break

                    model = genai.GenerativeModel(selected_model)

                    # ì´ë¯¸ì§€ë¥¼ ë°”ì´ë„ˆë¦¬ë¡œ ë³€í™˜
                    image_data = uploaded_chart.getvalue()

                    # ì°¨íŠ¸ ë¶„ì„ í”„ë¡¬í”„íŠ¸
                    analysis_prompt = """ì´ ì°¨íŠ¸ëŠ” ì£¼ì‹ ê¸°ìˆ ì  ë¶„ì„ ì°¨íŠ¸ì…ë‹ˆë‹¤.

ë‹¤ìŒ í•­ëª©ë“¤ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. **í˜„ì¬ ì¶”ì„¸** - ìƒìŠ¹/í•˜ë½/íš¡ë³´ ì¤‘ ì–´ëŠ ê²ƒì¸ê°€?
2. **ì£¼ìš” ì €í•­ì„ /ì§€ì§€ì„ ** - ì–´ë””ì— ìˆëŠ”ê°€?
3. **ê¸°ìˆ ì  ì‹ í˜¸** - ë§¤ìˆ˜/ë§¤ë„ ì‹ í˜¸ê°€ ë³´ì´ëŠ”ê°€?
4. **ê±°ë˜ëŸ‰** - ê±°ë˜ëŸ‰ ì¶”ì„¸ëŠ” ì–´ë–¤ê°€?
5. **íˆ¬ì ì¡°ì–¸** - í˜„ì¬ ì§„ì…/ì²­ì‚°í•˜ê¸° ì¢‹ì€ íƒ€ì´ë°ì¸ê°€?

ëª¨ë“  ë¶„ì„ì€ í•œêµ­ì–´ë¡œ ìƒì„¸í•˜ê²Œ ì œê³µí•´ì£¼ì„¸ìš”."""

                    response = model.generate_content([analysis_prompt, image])
                    analysis_result = response.text

                    st.success("ë¶„ì„ ì™„ë£Œ!")
                    st.markdown(analysis_result)

                except Exception as e:
                    st.error(f"ì°¨íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {e}")

# ==========================================
# [íƒ­ 2] ë‰´ìŠ¤ ê¸°ë°˜ ë¶„ì„
# ==========================================
with tab2:
    st.subheader("ì£¼ì‹ ë‰´ìŠ¤ ë¶„ì„")
    st.write("ì£¼ì‹ ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ì…ë ¥í•˜ë©´ AIê°€ ì£¼ê°€ì— ë¯¸ì¹  ì˜í–¥ì„ ë¶„ì„í•©ë‹ˆë‹¤.")

    news_input = st.text_area(
        "ë¶„ì„í•  ë‰´ìŠ¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
        placeholder="ì˜ˆ: ì‚¼ì„±ì „ìê°€ ì‹ ì œí’ˆ ë°œí‘œë¥¼ í–ˆìŠµë‹ˆë‹¤. AI ì¹©ì˜ ì„±ëŠ¥ì´ ê¸°ì¡´ ì œí’ˆ ëŒ€ë¹„ 50% í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤...",
        height=150
    )

    news_ticker = st.text_input(
        "í•´ë‹¹ ì¢…ëª© ì½”ë“œ (ì„ íƒì‚¬í•­)",
        placeholder="ì˜ˆ: NVDA, TSLA"
    )

    if st.button("ğŸ“Š ë‰´ìŠ¤ ì˜í–¥ë„ ë¶„ì„", key="analyze_news"):
        if not news_input.strip():
            st.warning("ë‰´ìŠ¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        else:
            with st.spinner("ë‰´ìŠ¤ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                try:
                    # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì„ íƒ
                    available_models = [m.name for m in genai.list_models() if "generateContent" in m.supported_generation_methods]
                    model_priority = ["gemini-2.0-flash", "gemini-1.5-flash", "gemini-1.5-pro"]
                    selected_model = "gemini-1.5-flash"

                    for model_name in model_priority:
                        if any(model_name in m for m in available_models):
                            selected_model = model_name
                            break

                    model = genai.GenerativeModel(selected_model)

                    # ë‰´ìŠ¤ ë¶„ì„ í”„ë¡¬í”„íŠ¸
                    ticker_context = f"ì¢…ëª©: {news_ticker}\n" if news_ticker else ""
                    analysis_prompt = f"""ë‹¹ì‹ ì€ ê¸ˆìœµ ë¶„ì„ê°€ì…ë‹ˆë‹¤.

{ticker_context}ë‹¤ìŒ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:

"{news_input}"

ì´ ë‰´ìŠ¤ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **ë‰´ìŠ¤ ìš”ì•½** - ì´ ë‰´ìŠ¤ì˜ í•µì‹¬ì€ ë¬´ì—‡ì¸ê°€?
2. **ê¸ì •/ë¶€ì • ì˜í–¥** - ì£¼ê°€ì— ê¸ì •ì ì¸ì§€ ë¶€ì •ì ì¸ì§€?
3. **ì˜í–¥ë„ ìˆ˜ì¹˜** (1~10) - ì£¼ê°€ì— ì–¼ë§ˆë‚˜ í° ì˜í–¥ì„ ë¯¸ì¹  ê²ƒ ê°™ì€ê°€?
4. **ì˜í–¥ë°›ì„ ì—…ì¢…/ì¢…ëª©** - ì–´ë–¤ ì—…ì¢…ì´ë‚˜ ì¢…ëª©ì´ ì˜í–¥ë°›ì„ ê²ƒì¸ê°€?
5. **íˆ¬ì ì „ëµ** - ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì–´ë–¤ íˆ¬ì ì „ëµì„ ì·¨í•´ì•¼ í•˜ëŠ”ê°€?
6. **ì£¼ì˜ì‚¬í•­** - íˆ¬ìí•  ë•Œ ì£¼ì˜í•  ì ì€ ë¬´ì—‡ì¸ê°€?

ëª¨ë“  ë¶„ì„ì€ í•œêµ­ì–´ë¡œ ìƒì„¸í•˜ê³  ê°ê´€ì ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”."""

                    response = model.generate_content(analysis_prompt)
                    news_analysis = response.text

                    st.success("ë¶„ì„ ì™„ë£Œ!")
                    st.markdown(news_analysis)

                except Exception as e:
                    st.error(f"ë‰´ìŠ¤ ë¶„ì„ ì‹¤íŒ¨: {e}")
